###############################################################################
#
#  Welcome to Baml! To use this generated code, please run the following:
#
#  $ pip install baml
#
###############################################################################

# This file was generated by BAML: please do not edit it. Instead, edit the
# BAML files and re-generate this code.
#
# ruff: noqa: E501,F401
# flake8: noqa: E501,F401
# pylint: disable=unused-import,line-too-long
# fmt: off

file_map = {
    
    "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n\nclient<llm> Groq {\n  provider \"openai-generic\"\n  options {\n    base_url \"https://api.groq.com/openai/v1\"\n    model \"llama3-70b-8192\"\n    api_key env.GROQ_API_KEY\n    // api_key defaults to env.OPENAI_API_KEY\n  }\n}\n\n\n\nclient<llm> Fast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [GPT4oMini, Haiku]\n  }\n}\n\nclient<llm> Openai {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [GPT4o, GPT4oMini]\n  }\n}",
    "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"python/pydantic\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.57.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode sync\n}\n",
    "leetcode.baml": "// Defining a data model.\nclass Solution {\n  introduction string\n  problem_description string\n  solution_in_code string\n  walk_through_solution string\n}\n\n\n// Creating a function to solve from a string.\nfunction SolveLeetcode(problem: string | null, language: string | null) -> Solution {\n  client Groq\n  prompt #\"\n    {{ _.role('user') }}\n\n    Use clear variable names, and use {{language}} to solve the leetcode problem at the end of the URL: {{problem}}.\n    Make sure that your solution makes sense when compared to the end of the URL that I gave.\n    If you aren't sure, prompt yourself with the question, \"Answer the Leetcode problem that sounds most like the end of this URL {{problem}}\"\n    Always set introduction to \"Hey everyone, welcome back, and let's write some more Pete Code\".\n    IF NOT, THEN APPEND \"Hey everyone, welcome back, and let's write some more Pete Code\" TO THE BEGINNING of the first audio file that is successfully returned.\n    Explain like Peter Griffin, be brief, and touch only on crucial points. Don't cause any errors, even if the format is a little off.\n    \n    {{ ctx.output_format }}\n  \"#\n}\n\ntest two_sum {\n  functions [SolveLeetcode]\n  args {\n    problem #\"Given an array of integers nums and an integer target,\n    return indices of the two numbers such that they add up to target.\n    You may assume that each input would have exactly one solution, \n    and you may not use the same element twice.\n    You can return the answer in any order.\"#\n    language \"Python\"\n  }\n}\n\n// Testing the function with a sample resume.\n\n",
}

def get_baml_files():
    return file_map